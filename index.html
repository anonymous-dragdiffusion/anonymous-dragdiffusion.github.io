<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>
<link href="https://fonts.googleapis.com/css2?family=Open+Sans&display=swap"
      rel="stylesheet">
<link rel="stylesheet" type="text/css" href="./drag_diffusion_resources/style.css" media="screen"/>

<html lang="en">
<head>
  	<title>DragDiffusion: Harnessing Diffusion Models for Interactive Point-based Image Editing</title>
      <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/
          if you update and want to force Facebook to re-scrape. -->
  	<meta property="og:image" content="Path to my teaser.jpg"/>
  	<meta property="og:title" content="DragDiffusion: Harnessing Diffusion Models for Interactive Point-based Image Editing" />
  	<meta property="og:description" content="Paper description." />
    <!-- Twitter automatically scrapes this. Go to https://cards-dev.twitter.com/validator?
        if you update and want to force Twitter to re-scrape. -->
    <meta property="twitter:card"          content="summary" />
    <meta property="twitter:title"         content="DragDiffusion: Harnessing Diffusion Models for Interactive Point-based Image Editing" />
    <meta property="twitter:description"   content="" />
    <meta property="twitter:image"         content="Path to my teaser.jpg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Add your Google Analytics tag here -->
    <script async
            src="https://www.googletagmanager.com/gtag/js?id=UA-97476543-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());
        gtag('config', 'UA-97476543-1');
    </script>

    <!-- enable math -->
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
    </script>
    <script type="text/javascript"
        src="http://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>

</head>

<body>
<div class="container">
    <div class="title" display="block">
        <b>
        DragDiffusion: Harnessing Diffusion Models
        <br>
        for Interactive Point-based Image Editing
        </b>
    </div>

    <!-- <div class="venue">
        In Conference 20XX
    </div> -->

    <br><br>

    <h1>Abstract</h1>
    <p style="width: 80%;text-align: justify">
        Accurate and controllable image editing is a challenging task that has attracted significant attention recently.
        Notably, DragGAN developed by Pan et al (2023) is an interactive point-based image editing framework that achieves
        impressive editing results with pixel-level precision. However, due to its reliance on generative adversarial networks (GANs),
        its generality is limited by the capacity of pretrained GAN models.
        In this work, we extend this editing framework to diffusion models and propose a novel approach DragDiffusion.
        By harnessing large-scale pretrained diffusion models, we greatly enhance the applicability of interactive point-based editing
        on both real and diffusion-generated images.
        Unlike other diffusion-based editing methods that provide guidance on diffusion latents of multiple time steps,
        our approach achieves efficient yet accurate spatial control by optimizing the latent of only one time step.
        This novel design is motivated by our observations that UNet features at a specific time step provides
        sufficient semantic and geometric information to support the drag-based editing.
        Moreover, we introduce two additional techniques, namely identity-preserving fine-tuning and reference-latent-control,
        to further preserve the identity of the original image.
        Lastly, we present a challenging benchmark dataset called DragBench---the first benchmark to evaluate
        the performance of interactive point-based image editing methods.
        Experiments across a wide range of challenging cases
        (e.g., images with multiple objects, diverse object categories, various styles, etc.)
        demonstrate the versatility and generality of DragDiffusion. The code and the DragBench dataset will be released.
    </p>
    <br>

    <hr>
    <br>
    <h1>Motivation</h1>
    <div class="img-with-text">
        <img width="700" src="./drag_diffusion_resources/motivation_fig_v3.jpg"/>
    </div>
    <br><br>
    <p style="width: 80%;text-align: justify">
        Given two frames from a video simulating the original
        and the "dragged" images,
        we visualize the UNet feature maps of different diffusion steps
        using principal component analysis (PCA).
        We find that there exists a single diffusion step
        (e.g., t=35 in this case) such that the UNet feature maps
        at this step alone contains sufficient semantic and geometric information
        to support structure-oriented spatial control such as drag-based editing.
        This observation motivates our novel method design
        of optimizing the diffusion latent of only one time step.
    </p>
    <br>
    <hr>

    <h1>Method</h1>
    <div class="img-with-text">
        <img width="900" src="./drag_diffusion_resources/method_overview.jpg"/>
    </div>
    <br><br>
    <p style="width: 80%;text-align: justify">
        Our approach constitutes three steps:
        (1) we conduct identity-preserving fine-tuning on the UNet of the
        diffusion model given the input image;
        (2) according to the user's dragging instruction,
        we optimize the latent obtained from DDIM inversion on the input image.
        (3) we apply DDIM denoising guided by our reference-latent-control
        on $\hat{z}_{t}$ to obtain the final editing result $\hat{z}_{0}$.
    </p>
    <br>
    <hr>

    <h1>Dragging Trajectories (Real Images)</h1>
    <div class="img-with-text">
        <figcaption style="font-size:20px">user edit</figcaption>
        <img width="200" height="200" src="./drag_diffusion_resources/user_edit_dog.png"/>
    </div>
    <div class="img-with-text">
        <figcaption style="font-size:20px">user edit</figcaption>
        <img width="200" height="200" src="./drag_diffusion_resources/user_edit_sculpture.png"/>
    </div>
    <div class="img-with-text">
        <figcaption style="font-size:20px">user edit</figcaption>
        <img width="200" height="200" src="./drag_diffusion_resources/user_edit_oilpaint.png"/>
    </div>
    <div class="img-with-text">
        <figcaption style="font-size:20px">user edit</figcaption>
        <img width="200" height="200" src="./drag_diffusion_resources/user_edit_oilpaint_mountain.png"/>
    </div>
    <div class="img-with-text">
        <figcaption style="font-size:20px">user edit</figcaption>
        <img width="200" height="200" src="./drag_diffusion_resources/user_edit_cat_dog.png"/>
    </div>

    <br><br>

    <div class="video-with-text">
        <figcaption style="font-size:20px">dragging trajectory</figcaption>
        <video width="200" height="200" controls>
            <source src="./drag_diffusion_resources/dog.mp4" type="video/mp4">
        </video>
    </div>
    <div class="video-with-text">
        <figcaption style="font-size:20px">dragging trajectory</figcaption>
        <video width="200" height="200" controls>
            <source src="./drag_diffusion_resources/sculpture.mp4" type="video/mp4">
        </video>
    </div>
    <div class="video-with-text">
        <figcaption style="font-size:20px">dragging trajectory</figcaption>
        <video width="200" height="200" controls>
            <source src="./drag_diffusion_resources/oilpaint_shorter.mp4" type="video/mp4">
        </video>
    </div>
    <div class="video-with-text">
        <figcaption style="font-size:20px">dragging trajectory</figcaption>
        <video width="200" height="200" controls>
            <source src="./drag_diffusion_resources/oilpaint_mountain.mp4" type="video/mp4">
        </video>
    </div>
    <div class="video-with-text">
        <figcaption style="font-size:20px">dragging trajectory</figcaption>
        <video width="200" height="200" controls>
            <source src="./drag_diffusion_resources/cat_dog.mp4" type="video/mp4">
        </video>
    </div>

    <br>
    <br>
    <hr>


    <h1>Dragging Trajectories (Generated Images)</h1>
    <div class="img-with-text">
        <figcaption style="font-size:20px">user edit</figcaption>
        <img width="250" height="250" src="./drag_diffusion_resources/user_edit_CF1.png"/>
    </div>
    <div class="video-with-text">
        <figcaption style="font-size:20px">dragging trajectory</figcaption>
        <video width="250" height="250" controls>
            <source src="./drag_diffusion_resources/CF1.mp4" type="video/mp4">
        </video>
    </div>
    <div class="img-with-text">
        <figcaption style="font-size:20px">user edit</figcaption>
        <img width="250" height="250" src="./drag_diffusion_resources/user_edit_MR1.png"/>
    </div>
    <div class="video-with-text">
        <figcaption style="font-size:20px">dragging trajectory</figcaption>
        <video width="250" height="250" controls>
            <source src="./drag_diffusion_resources/MR1.mp4" type="video/mp4">
        </video>
    </div>

    <br>

    <div class="img-with-text">
        <figcaption style="font-size:20px">user edit</figcaption>
        <img width="250" height="384" src="./drag_diffusion_resources/user_edit_CF2.png"/>
    </div>
    <div class="video-with-text">
        <figcaption style="font-size:20px">dragging trajectory</figcaption>
        <video width="250" height="384" controls>
            <source src="./drag_diffusion_resources/CF2.mp4" type="video/mp4">
        </video>
    </div>
    <div class="img-with-text">
        <figcaption style="font-size:20px">user edit</figcaption>
        <img width="250" height="384" src="./drag_diffusion_resources/user_edit_MR2.png"/>
    </div>
    <div class="video-with-text">
        <figcaption style="font-size:20px">dragging trajectory</figcaption>
        <video width="250" height="384" controls>
            <source src="./drag_diffusion_resources/MR2.mp4" type="video/mp4">
        </video>
    </div>

    <br>

    <div class="img-with-text">
        <figcaption style="font-size:20px">user edit</figcaption>
        <img width="384" height="250" src="./drag_diffusion_resources/user_edit_CF3.png"/>
    </div>
    <div class="video-with-text">
        <figcaption style="font-size:20px">dragging trajectory</figcaption>
        <video width="384" height="250" controls>
            <source src="./drag_diffusion_resources/CF3.mp4" type="video/mp4">
        </video>
    </div>

    <br>
    <br>
    <hr>


    <h1>More Dragging Results</h1>
    <h2>General objects</h2>
    <img style="width: 80%;" src="./drag_diffusion_resources/general_object.jpg"
         alt="Results figure"/>

    <h2>Arts</h2>
    <img style="width: 80%;" src="./drag_diffusion_resources/art.jpg"
         alt="Results figure"/>

    <h2>Animals</h2>
    <img style="width: 80%;" src="./drag_diffusion_resources/animal.jpg"
         alt="Results figure"/>

    <h2>Scenes</h2>
    <img style="width: 80%;" src="./drag_diffusion_resources/scene.jpg"
         alt="Results figure"/>


    <br><br>
</div>

</body>

</html>
